{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit (NLTK)\n",
    "\n",
    "**NLTK** is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to [over 50 corpora and lexical resources](http://www.nltk.org/nltk_data/) such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "\n",
    "http://www.nltk.org/\n",
    "\n",
    "NLTK library documentation (reference) = *Use it to look up how to use a particular NLTK library function*\n",
    "* https://www.nltk.org/api/nltk.html\n",
    "\n",
    "---\n",
    "\n",
    "NLTK wiki (collaboratively edited documentation):\n",
    "* https://github.com/nltk/nltk/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book: Natural Language Processing with Python \n",
    "\n",
    "NLTK book provides a practical introduction to programming for language processing.\n",
    "\n",
    "Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.\n",
    "\n",
    "Online: http://www.nltk.org/book/\n",
    "\n",
    "* we will start with Chapter 1: [\"Language Processing and Python\"](http://www.nltk.org/book/ch01.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for the notebook \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Getting started\n",
    "\n",
    "NLTK book: http://www.nltk.org/book/ch01.html#getting-started-with-nltk\n",
    "\n",
    "* Loading NLTK (Python module)\n",
    "* Downloading NLTK language resources (corpora, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use a Python library, we need to import (load) it\n",
    "\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check what NLTK version we have (for easier troubleshooting and reproducibility)\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your NLTK version is lower than 3.4.3 please update if possible.\n",
    "\n",
    "# Updating in Anaconde can be done using this command: \n",
    "# conda update nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.Text\n",
    "\n",
    "**`ntlk.Text` is a simple NLTK helper for loading and exploring textual content (a sequence of words / string tokens):**\n",
    "\n",
    "... intended to support initial exploration of texts (via the interactive console). It can perform a variety of analyses on the text’s contexts (e.g., counting, concordancing, collocation discovery), and display the results.\n",
    "\n",
    "Documentation: [nltk.Text](https://www.nltk.org/api/nltk.html#nltk.text.Text)\n",
    "* lists what we can do with text once it is loaded into nltk.Text(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can try a simple example:\n",
    "\n",
    "my_word_list = [\"This\", \"is\", \"just\", \"an\", \"example\", \"Another\", \"example\", \"here\"]\n",
    "my_text = nltk.Text(my_word_list)\n",
    "\n",
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times does the word \"example\" appear?\n",
    "my_text.count(\"example\")\n",
    "\n",
    "# Notes:\n",
    "#  - my_text = our text, processed (loaded) by NLTK\n",
    "#     - technically: a Python object\n",
    "#  - my_text.count(...) = requesting the object to perform a .count(...) function and return the result\n",
    "#     - technically: calling a .count() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count works on tokens (full words in this case)\n",
    "my_text.count('exam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'exam' in my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'example' in my_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "Let's convert a text string into nltk.Text.\n",
    "First, we need to split it into tokens (to *tokenize* it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to download a package containing punctuation before we can tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting text into tokens (words, ...) = tokenizing\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "excerpt = \"NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”\"\n",
    "tokens = word_tokenize(excerpt)\n",
    "\n",
    "tokens[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text2 = nltk.Text(tokens)\n",
    "\n",
    "print(my_text2.count(\"NLTK\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading NLTK language resources\n",
    "\n",
    "NLTK also contains many language resources (corpora, ...) but you have select and download them separately (in order to save disk space and only download what is needed).\n",
    "\n",
    "Let's download text collections used in the NLTK book: \n",
    "* `nltk.download(\"book\")`\n",
    "\n",
    "Note: you can also download resources interactively:\n",
    "* `nltk.download()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a big download of all book packages\n",
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After downloading the reources we still need to import them\n",
    "\n",
    "# Let's import all NLTK book resource (*)\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Exploring textual content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1, ... resources are of type nltk.Text (same as in the earlier example):\n",
    "\n",
    "type(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run all methods that nltk.Text has.\n",
    "\n",
    "# Count words:\n",
    "print(text1.count(\"whale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.concordance\n",
    "\n",
    "# Print concordance view (occurences of a word, in context):\n",
    "text1.concordance(\"discover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4.concordance(\"nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.similar\n",
    "\n",
    "# Print words that appear in similar context as \"nation\".\n",
    "text4.similar(\"nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.common_contexts\n",
    "\n",
    "# Find contexts common to all given words\n",
    "text1.common_contexts([\"day\", \"night\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Python lists\n",
    "\n",
    "A *list* contains multiple values in an ordered sequence.\n",
    "\n",
    "More about Python lists:\n",
    "* https://automatetheboringstuff.com/chapter4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.Text is also a list - can do everything we can do with lists (access parts of it, ...)\n",
    "\n",
    "# What's the 1st occurence of \"He\" in the text?\n",
    "#  - note: Python is case sensitive (unless you take care of it - e.g. convert all text to lowercase)\n",
    "\n",
    "print(text1.index(\"He\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The word at position #42\n",
    "#  - note: list indexes start from 0\n",
    "\n",
    "print(text1[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text1[42:52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration\n",
    "\n",
    "* Dispersion plots (distribution of words throughout the text)\n",
    "* Generating text (based on example)\n",
    "\n",
    "### Visualizing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dispersion plot\n",
    "\n",
    "# source: Inaugural Address Corpus\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"duty\", \"freedom\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(text4.dispersion_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text\n",
    "\n",
    "Note: depending on your version of NLTK `generate()` functionality may or may not work (NLTK version 3.7.4 or newer is required).\n",
    "* In case it does not work, please see subsection \"Saved version of generate() results\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text (based on example)\n",
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.generate\n",
    "\n",
    "# we need to supply seed words\n",
    "text1.generate(text_seed = [\"Why\", \"is\", \"it\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**NLTK `generate()` builds a [trigram] language model from the supplied text** (words are generated based on previous two words).\n",
    "\n",
    "For more information see nltk.lm: https://www.nltk.org/api/nltk.lm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saved version of `generate()` results:**\n",
    "    \n",
    "`text1.generate(text_seed = [\"Why\", \"is\", \"it\"])`\n",
    "\n",
    "*Building ngram index...*\n",
    "\n",
    "```\n",
    "Why is it stripped off from some mountain torrent we had flip ? , so as to\n",
    "preserve all his might had in former years abounding with them , they\n",
    "toil with their lances , strange tales of Southern whaling .\n",
    "conceivable that this fine old Dutch Fishery , a most wealthy example\n",
    "of the sea - captain orders me to admire the magnanimity of the whole\n",
    ", and many whalemen , but dumplings ; good white cedar of the ship\n",
    "casts off her cables ; and chewed it noiselessly ; and though there\n",
    "are birds called grey albatrosses ; and yet faster\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(text1.generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your turn!\n",
    "\n",
    "Choose some text and **explore it using NLTK** (following the examples in this notebook).\n",
    "\n",
    "**Write code in notebook cells below**.\n",
    "* add more cells (use \"+\" icon) if necessary\n",
    "\n",
    "You may use NLTK text corpora or load your own text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
