{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd01521",
   "metadata": {
    "id": "abd01521"
   },
   "source": [
    "# Reading Data\n",
    "\n",
    "There are various file formats, how do we make a sense of them all?\n",
    "\n",
    "* There are archive/compression formats such as .zip, .rar, .7z, .tar those hold other files.\n",
    "* There are text formats such as .txt, .csv, .json, .tsv - those can be read by humans in a text editor\n",
    "* There are binary formats such as .exe, .jpg, .png - those are not human readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf08d1",
   "metadata": {
    "id": "06bf08d1"
   },
   "source": [
    "### Reading text files\n",
    "\n",
    "In this section we will read a simple text file. It contains text from the start of English Wikipedia article about Riga: https://en.wikipedia.org/wiki/Riga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac177026",
   "metadata": {
    "id": "ac177026"
   },
   "outputs": [],
   "source": [
    "filename = \"data/riga_wikipedia.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdded79",
   "metadata": {
    "id": "0bdded79"
   },
   "outputs": [],
   "source": [
    "# open the file for reading\n",
    "file_1 = open(filename)\n",
    "\n",
    "# read contents of the file\n",
    "data = file_1.read()\n",
    "\n",
    "# close the file\n",
    "file_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b67e7",
   "metadata": {
    "id": "0c5b67e7"
   },
   "source": [
    "Note: The above action (reading a local file) will fail if you execute it in Google Colab. \n",
    "\n",
    "If that's the case, uncomment (remove # marks from start of the line) the code below that reads the same file from a remote web location (a Github repository in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db22d13",
   "metadata": {
    "id": "2db22d13"
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"https://raw.githubusercontent.com/ValRCS/BSSDH_22/main/notebooks/data/riga_wikipedia.txt\"\n",
    "\n",
    "# response = requests.get(url)\n",
    "# data = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c83bfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56c83bfd",
    "outputId": "1e38cbc2-253f-4b16-f123-786160c1c7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riga (/ˈriːɡə/; Latvian: Rīga [ˈriːɡa] (listen), Livonian: Rīgõ) is the capital of Latvia and is hom\n"
     ]
    }
   ],
   "source": [
    "# print the first 100 characters of the file\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b91449",
   "metadata": {
    "id": "30b91449"
   },
   "outputs": [],
   "source": [
    "# split text into tokens (words)\n",
    "words = data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a4c041",
   "metadata": {
    "id": "e6a4c041",
    "outputId": "20d1943f-439b-4638-8dd6-4ae12cb9a963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "# count the number of tokens in text\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6696dd23",
   "metadata": {
    "id": "6696dd23",
    "outputId": "417a5525-8f4c-4237-a709-2e4a4407f65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Riga', '(/ˈriːɡə/;', 'Latvian:', 'Rīga', '[ˈriːɡa]', '(listen),', 'Livonian:', 'Rīgõ)', 'is', 'the', 'capital', 'of', 'Latvia', 'and', 'is', 'home', 'to', '671,000', 'inhabitants', '[10][11][12]', 'which', 'is', 'a', 'third', 'of', \"Latvia's\", 'population.', 'Being', 'significantly', 'larger', 'than', 'other', 'cities', 'of', 'Latvia,', 'Riga', 'is', 'the', \"country's\", 'primate', 'city.', 'It', 'is', 'also', 'the', 'largest', 'city', 'in', 'the', 'three']\n"
     ]
    }
   ],
   "source": [
    "# print the first 50 tokens\n",
    "print(words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f41a77",
   "metadata": {
    "id": "63f41a77"
   },
   "source": [
    "### Counting word frequency\n",
    "\n",
    "Here we will use Python's Counter object (from Python collections library) to determine word frequency of the text. \n",
    "\n",
    "https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3391228",
   "metadata": {
    "id": "e3391228"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac286d47",
   "metadata": {
    "id": "ac286d47"
   },
   "outputs": [],
   "source": [
    "c = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b41935a",
   "metadata": {
    "id": "2b41935a",
    "outputId": "5a49e01f-f2f7-4dcb-c40e-be279e075fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 21), ('of', 13), ('is', 11), ('Riga', 9), ('and', 9), ('a', 5), ('in', 5), ('Baltic', 5), ('European', 5), ('World', 4), ('home', 3), ('to', 3), ('city', 3), ('was', 3), ('Union', 3), ('It', 2), ('largest', 2), ('three', 2), ('The', 2), ('lies', 2)]\n"
     ]
    }
   ],
   "source": [
    "# print the 20 most common words (tokens)\n",
    "print(c.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de34be2e",
   "metadata": {
    "id": "de34be2e",
    "outputId": "21e9bd65-9631-4839-989d-22781b51b0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 21\n",
      "of: 13\n",
      "is: 11\n",
      "Riga: 9\n",
      "and: 9\n",
      "a: 5\n",
      "in: 5\n",
      "Baltic: 5\n",
      "European: 5\n",
      "World: 4\n",
      "home: 3\n",
      "to: 3\n",
      "city: 3\n",
      "was: 3\n",
      "Union: 3\n",
      "It: 2\n",
      "largest: 2\n",
      "three: 2\n",
      "The: 2\n",
      "lies: 2\n"
     ]
    }
   ],
   "source": [
    "# a nicer way of printing counter results using a *for* cycle\n",
    "\n",
    "for token, count in c.most_common(20):\n",
    "    print(f\"{token}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf4f58",
   "metadata": {
    "id": "5ecf4f58"
   },
   "source": [
    "Notice how words may appear in both lowercase (\"the\") and uppercase (\"The\"). You may want to normalize the text by converting it all to lowercase and do other clean-up steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d1d0b",
   "metadata": {
    "id": "f49d1d0b"
   },
   "source": [
    "### Reading TSV files\n",
    "\n",
    "Corpora that we will work with are located in archived TSV (Tab-separated-values) files:\n",
    "https://github.com/ValRCS/BSSDH_22/tree/main/corpora\n",
    "\n",
    "These files consist of rows (records) that contain one or more values separated by \"Tab\" characters.\n",
    "\n",
    "We will use Pandas library to read a TSV file that contains a smaller version of the \"lv_old_newspapers.zip\" corpus: https://github.com/ValRCS/BSSDH_22/blob/main/corpora/lv_old_newspapers_5k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5194e455",
   "metadata": {
    "id": "5194e455"
   },
   "outputs": [],
   "source": [
    "import pandas  \n",
    "# common alternative \n",
    "# import pandas as pd\n",
    "# this would let you save 4 characters each time you need some pandas functionality you would write pd instead of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787b4e8f",
   "metadata": {
    "id": "787b4e8f"
   },
   "outputs": [],
   "source": [
    "filename = \"../corpora/lv_old_newspapers_5k.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "694238e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "694238e0",
    "outputId": "935c4700-137f-42ec-fa7c-c1e40c60e63c"
   },
   "outputs": [],
   "source": [
    "# read the tab-separated file (\"sep\" parameter tells Pandas that values in the file\n",
    "# are separated with the \"tab\" character.\n",
    "\n",
    "df_1 = pandas.read_csv(filename, sep=\"\\t\") # instead of df_1 we could use another name for our variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89655e67",
   "metadata": {
    "id": "89655e67"
   },
   "source": [
    "Note: The above action (reading a local file) will fail if you execute it in Google Colab.\n",
    "\n",
    "We have two different approaches then:\n",
    "\n",
    "1. Upload file to Google Colab (remember this is temporary).Read it just like you would on a local computer. \n",
    "\n",
    "2. Download file(s) from web address, instead of file path we will use a URL - Uniform Resource Locator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "q-lAt9XM54mF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "q-lAt9XM54mF",
    "outputId": "fc5e2488-7ba7-4a3f-f32a-ebf5fa36cc81"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lv_old_newspapers_5k.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cy/880bvxy90j33f79df17qysyr0000gn/T/ipykernel_52337/1081227825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Assuming file has been uploaded it will be found in current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lv_old_newspapers_5k.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_changed_stuff_/LNB - Python workshop/venv/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lv_old_newspapers_5k.tsv'"
     ]
    }
   ],
   "source": [
    "# Approach 1\n",
    "# Assuming file has been uploaded it will be found in current directory\n",
    "file_path = \"lv_old_newspapers_5k.tsv\"\n",
    "df_1 = pandas.read_csv(file_path, sep=\"\\t\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69605e00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "69605e00",
    "outputId": "bad16782-8d8c-4e76-fac2-5c8840917cb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>rekurzeme.lv</td>\n",
       "      <td>2008/09/04</td>\n",
       "      <td>\"Viņa pirmsnāves zīmītē bija rakstīts vienīgi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>diena.lv</td>\n",
       "      <td>2012/01/10</td>\n",
       "      <td>info@zurnalistiem.lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>bauskasdzive.lv</td>\n",
       "      <td>2007/12/27</td>\n",
       "      <td>Bhuto, kas Pakistānā no trimdas atgriezās tika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>bauskasdzive.lv</td>\n",
       "      <td>2008/10/08</td>\n",
       "      <td>Plkst. 4.00 Samoilovs / Pļaviņš (pludmales vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>diena.lv</td>\n",
       "      <td>2011/10/05</td>\n",
       "      <td>CVK bija vērsusies Skaburska, lūdzot izskaidro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language           Source        Date  \\\n",
       "0  Latvian     rekurzeme.lv  2008/09/04   \n",
       "1  Latvian         diena.lv  2012/01/10   \n",
       "2  Latvian  bauskasdzive.lv  2007/12/27   \n",
       "3  Latvian  bauskasdzive.lv  2008/10/08   \n",
       "4  Latvian         diena.lv  2011/10/05   \n",
       "\n",
       "                                                Text  \n",
       "0  \"Viņa pirmsnāves zīmītē bija rakstīts vienīgi ...  \n",
       "1                               info@zurnalistiem.lv  \n",
       "2  Bhuto, kas Pakistānā no trimdas atgriezās tika...  \n",
       "3  Plkst. 4.00 Samoilovs / Pļaviņš (pludmales vol...  \n",
       "4  CVK bija vērsusies Skaburska, lūdzot izskaidro...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach 2 reading from a web address \n",
    "url = \"https://github.com/ValRCS/BSSDH_22/raw/main/corpora/lv_old_newspapers_5k.tsv\"\n",
    "\n",
    "df_2 = pandas.read_csv(url, sep=\"\\t\") \n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xz5bWs-G6kgp",
   "metadata": {
    "id": "Xz5bWs-G6kgp"
   },
   "source": [
    "### How to read data from a subfolder (in Colab)\n",
    "in Colab we have a subfolder called sample_data\n",
    "Let's read a file called README.md from there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ZW-x9YSZ7A6p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ZW-x9YSZ7A6p",
    "outputId": "2ba77fa8-39d9-4005-9d9b-3bf7d527351d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_data/README.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cy/880bvxy90j33f79df17qysyr0000gn/T/ipykernel_52337/1727782282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manother_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sample_data/README.md\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manother_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mreadme_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# file is automatically closed here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreadme_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/README.md'"
     ]
    }
   ],
   "source": [
    "another_path = \"sample_data/README.md\"\n",
    "with open(another_path) as f:\n",
    "    readme_text = f.read()\n",
    "# file is automatically closed here\n",
    "readme_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6aaa5",
   "metadata": {},
   "source": [
    "### Let's continue working with the dataframe (containing a text corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bcc2734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bcc2734",
    "outputId": "11ecb4bd-d0b8-4b93-e73e-e5f88d8ce9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "# the size of the corpus:\n",
    "\n",
    "print(len(df_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c5f4f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62c5f4f8",
    "outputId": "05a25c2e-5a39-4a67-a7ab-d786e2015231"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Viņa pirmsnāves zīmītē bija rakstīts vienīgi ...\n",
       "1                                 info@zurnalistiem.lv\n",
       "2    Bhuto, kas Pakistānā no trimdas atgriezās tika...\n",
       "3    Plkst. 4.00 Samoilovs / Pļaviņš (pludmales vol...\n",
       "4    CVK bija vērsusies Skaburska, lūdzot izskaidro...\n",
       "5    Apbalvojumus piešķir piemiņas zīmes valde Saei...\n",
       "6    - Amerikā biju uzaicināts viesoties ar visu ģi...\n",
       "7    Mūrniece gan saka, ka Lužkova bitēm Latvijas p...\n",
       "8    PĒDĒJĀ, kontrolēja PĀRDAUGAVAS telpu, izņemot ...\n",
       "9    Ar Ivaru tikāmies viņa dzimtajos \"Lazdiņos\" Za...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the Text column, show the first 10 entries\n",
    "\n",
    "df_1[\"Text\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eBJq74i47f-N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBJq74i47f-N",
    "outputId": "0adaf4f7-9def-4a13-930e-b7d2eeb00dd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get ALL of the text in one big string from a pandas column\n",
    "list_of_rows = list(df_1.Text)\n",
    "len(list_of_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aD-jSYH_7wMe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aD-jSYH_7wMe",
    "outputId": "4fe0f3b5-441d-4b91-8159-c29fa334f404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Viņa pirmsnāves zīmītē bija rakstīts vienīgi par smēķēšanas aizlieguma radītajiem rūpestiem,\" laikrakstam paskaidroja nelaiķa svainis Helmuts Ratmanns. \"Tā nebija vērsta pret viņa ģimeni vai politiķiem.\"',\n",
       " 'info@zurnalistiem.lv',\n",
       " 'Bhuto, kas Pakistānā no trimdas atgriezās tikai pirms diviem mēnešiem, uzstājās priekšvēlēšanu mītiņā, kas organizēts pirms nākamajā mēnesī gaidāmajām parlamenta vēlēšanām.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what we have in first 3 rows\n",
    "list_of_rows[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "EA7Nd7sR71zq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "EA7Nd7sR71zq",
    "outputId": "1c647769-8bc3-476c-e1ed-bc0958ec8bc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Viņa pirmsnāves zīmītē bija rakstīts vienīgi par smēķēšanas aizlieguma radītajiem rūpestiem,\" laikrakstam paskaidroja nelaiķa svainis Helmuts Ratmanns. \"Tā nebija vērsta pret viņa ģimeni vai politiķiem.\"\\ninfo@zurnalistiem.lv\\nBhuto, kas Pakistānā no '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = \"\\n\".join(list_of_rows) # we join all rows into one big string \n",
    "# separating each document with a newline, you could choose something else to join with\n",
    "all_text[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c46d3",
   "metadata": {
    "id": "e28c46d3"
   },
   "source": [
    "### Reading archived files\n",
    "\n",
    "Pandas can also read archived CSV and TSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d0af606",
   "metadata": {
    "id": "3d0af606"
   },
   "outputs": [],
   "source": [
    "filename_2 = \"../corpora/lv_old_newspapers.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d6803f9",
   "metadata": {
    "id": "1d6803f9"
   },
   "outputs": [],
   "source": [
    "# read the archived, tab-separated file (\"compression\" parameter tells\n",
    "# Pandas that this is a ZIP archived file).\n",
    "\n",
    "df_2 = pandas.read_csv(filename_2, sep=\"\\t\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c131a",
   "metadata": {
    "id": "589c131a"
   },
   "source": [
    "Note: The above action (reading a local file) will fail if you execute it in Google Colab.\n",
    "\n",
    "If that's the case, uncomment (remove # marks from start of the line) the code below that reads the same file from a remote web location (a Github repository in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cccef3e2",
   "metadata": {
    "id": "cccef3e2"
   },
   "outputs": [],
   "source": [
    "# url_2 = \"https://github.com/ValRCS/BSSDH_22/raw/main/corpora/lv_old_newspapers.zip\"\n",
    "#\n",
    "# df_2 = pandas.read_csv(url_2, sep=\"\\t\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9587588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9587588",
    "outputId": "ddff5277-83b1-4a33-fb15-3d23e692e405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319428\n"
     ]
    }
   ],
   "source": [
    "# the size of the corpus:\n",
    "\n",
    "print(len(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6525f55f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6525f55f",
    "outputId": "ad09cbde-81b2-42f8-951d-055753794f9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319418</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>bdaugava.lv</td>\n",
       "      <td>2010/01/16</td>\n",
       "      <td>Ceturtdien no rajona padomes ēkas tika svinīgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319419</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>nra.lv</td>\n",
       "      <td>2011/12/21</td>\n",
       "      <td>AFP vēsta, ka naktī uz otrdienu, jau piekto na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319420</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>db.lv</td>\n",
       "      <td>2011/12/02</td>\n",
       "      <td>TOP 500 ir vienīgais ikgadējais izdevums Latvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319421</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>diena.lv</td>\n",
       "      <td>2009/12/21</td>\n",
       "      <td>ka pati visu mūžu bijusi saistīta ar šo jomu. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319422</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>la.lv</td>\n",
       "      <td>2011/12/08</td>\n",
       "      <td>Prakse liecina, ka tādos gadījumos tiesu izpil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319423</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>ziemellatvija.lv</td>\n",
       "      <td>2008/01/30</td>\n",
       "      <td>Beigu beigās I. Klempere kopā ar dēlu mājās de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319424</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>db.lv</td>\n",
       "      <td>2012/01/03</td>\n",
       "      <td>Vienkāršā valodā tas nozīmē, ka investori par ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319425</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>la.lv</td>\n",
       "      <td>2011/08/27</td>\n",
       "      <td>– Visi mūsu projekti ir notikuši sadarbībā ar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319426</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>ziemellatvija.lv</td>\n",
       "      <td>2007/03/12</td>\n",
       "      <td>Pole atzina, ka par šo ziņojumu VM saņēmusi li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319427</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>bauskasdzive.lv</td>\n",
       "      <td>2011/07/07</td>\n",
       "      <td>Trešdienas, 6. jūlija, vakarā projekta vadītāj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Language            Source        Date  \\\n",
       "319418  Latvian       bdaugava.lv  2010/01/16   \n",
       "319419  Latvian            nra.lv  2011/12/21   \n",
       "319420  Latvian             db.lv  2011/12/02   \n",
       "319421  Latvian          diena.lv  2009/12/21   \n",
       "319422  Latvian             la.lv  2011/12/08   \n",
       "319423  Latvian  ziemellatvija.lv  2008/01/30   \n",
       "319424  Latvian             db.lv  2012/01/03   \n",
       "319425  Latvian             la.lv  2011/08/27   \n",
       "319426  Latvian  ziemellatvija.lv  2007/03/12   \n",
       "319427  Latvian   bauskasdzive.lv  2011/07/07   \n",
       "\n",
       "                                                     Text  \n",
       "319418  Ceturtdien no rajona padomes ēkas tika svinīgi...  \n",
       "319419  AFP vēsta, ka naktī uz otrdienu, jau piekto na...  \n",
       "319420  TOP 500 ir vienīgais ikgadējais izdevums Latvi...  \n",
       "319421  ka pati visu mūžu bijusi saistīta ar šo jomu. ...  \n",
       "319422  Prakse liecina, ka tādos gadījumos tiesu izpil...  \n",
       "319423  Beigu beigās I. Klempere kopā ar dēlu mājās de...  \n",
       "319424  Vienkāršā valodā tas nozīmē, ka investori par ...  \n",
       "319425  – Visi mūsu projekti ir notikuši sadarbībā ar ...  \n",
       "319426  Pole atzina, ka par šo ziņojumu VM saņēmusi li...  \n",
       "319427  Trešdienas, 6. jūlija, vakarā projekta vadītāj...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the last 10 entries\n",
    "\n",
    "df_2.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_HsCDJ8i8gZc",
   "metadata": {
    "id": "_HsCDJ8i8gZc"
   },
   "source": [
    "##  Reading other formats\n",
    "\n",
    "Pandas supports a wide variety of file formats\n",
    "\n",
    "Full list of formats is available here: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "\n",
    "For example to read EXCEL files you would use my_dataframe = pandas.read_excel(filepath)\n",
    "where filepath would be a string with file location or web address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OdccFugd9QKx",
   "metadata": {
    "id": "OdccFugd9QKx"
   },
   "source": [
    "## Question and Answer session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q4zGUWlX9TvF",
   "metadata": {
    "id": "Q4zGUWlX9TvF"
   },
   "source": [
    "## Task - read data into a dataframe from file for your language\n",
    "\n",
    "We have 3 different corpora files for your use.\n",
    "\n",
    "Addresses:\n",
    "\n",
    "* Estonian - https://github.com/ValRCS/BSSDH_22/raw/main/corpora/ee_old_newspapers.zip\n",
    "* Latvian - https://github.com/ValRCS/BSSDH_22/raw/main/corpora/lv_old_newspapers.zip\n",
    "* Ukrainian - https://github.com/ValRCS/BSSDH_22/raw/main/corpora/ua_old_newspapers.zip\n",
    "\n",
    "Load one of them in a dataframe. Check the length, shape, see first 15 entries and last 20 entries."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Reading_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
